{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a pretrained word-embedding (word2vec, glove or fasttext) for featurization instead of the bag-of-words model. Does this improve classification? How about combining the embedded words with the BoW model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/wine_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we modify the cleaned dataframe that the descriptions are all lower case and do not contain any stop words.  We then turn the sentence into an array to work with for later.  Some of the code applied in this section was adapted from the following article on cleaning data: https://medium.com/@chaimgluck1/have-messy-text-data-clean-it-with-simple-lambda-functions-645918fcc2fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']= df['description'].str.lower()\n",
    "df['description']= df['description'].apply(lambda elem: re.sub('[^a-zA-Z]',' ', elem)) \n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df['description'] = df['description'].apply(tokenizer.tokenize)\n",
    "\n",
    "stopword_list = stopwords.words('english')\n",
    "df['description'] = df['description'].apply(lambda elem: [word for word in elem if not word in stopword_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our pretrained model.  For this tasks we selected GoogleNews pretrained model with over 3 million words in the vocabulary. (This will not be included in the download file since it is 1.5GB, so it must be downloaded to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is loaded into memory, we will go through each description and vectorize the sentence.  For this, we will be adding together each word in the description and skipping it if the word is not in the vocabulary.  Another option is averaging out the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = []\n",
    "for description in df[\"description\"]:\n",
    "    sum_vector = np.zeros((300,))\n",
    "    for word in description:\n",
    "        if word in model.vocab:\n",
    "            sum_vector += model[word]\n",
    "    vectorized_sentences.append(sum_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify our dataframe such that the only thing left are the labels of points associated with wines in the first column, and the vectorized sentences of the wine descriptions in the next 300 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>-0.364258</td>\n",
       "      <td>0.786743</td>\n",
       "      <td>-0.038315</td>\n",
       "      <td>1.797501</td>\n",
       "      <td>-0.749458</td>\n",
       "      <td>-0.481781</td>\n",
       "      <td>2.205750</td>\n",
       "      <td>-2.917053</td>\n",
       "      <td>0.027161</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.048325</td>\n",
       "      <td>-1.840363</td>\n",
       "      <td>-1.043030</td>\n",
       "      <td>-3.078369</td>\n",
       "      <td>1.085205</td>\n",
       "      <td>0.373444</td>\n",
       "      <td>0.347908</td>\n",
       "      <td>-0.657639</td>\n",
       "      <td>1.683472</td>\n",
       "      <td>2.301544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>0.922775</td>\n",
       "      <td>1.643341</td>\n",
       "      <td>-1.001190</td>\n",
       "      <td>2.650461</td>\n",
       "      <td>-0.556315</td>\n",
       "      <td>1.640244</td>\n",
       "      <td>1.762878</td>\n",
       "      <td>-2.678284</td>\n",
       "      <td>0.507172</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.076820</td>\n",
       "      <td>-0.422913</td>\n",
       "      <td>-0.375568</td>\n",
       "      <td>0.862671</td>\n",
       "      <td>-0.212234</td>\n",
       "      <td>0.177979</td>\n",
       "      <td>2.442276</td>\n",
       "      <td>-1.439209</td>\n",
       "      <td>2.908058</td>\n",
       "      <td>2.351929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>-0.886719</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>-2.253662</td>\n",
       "      <td>2.624756</td>\n",
       "      <td>-0.522400</td>\n",
       "      <td>-0.135101</td>\n",
       "      <td>2.016785</td>\n",
       "      <td>-2.015633</td>\n",
       "      <td>2.668503</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.481445</td>\n",
       "      <td>-1.066376</td>\n",
       "      <td>-0.811798</td>\n",
       "      <td>0.280640</td>\n",
       "      <td>0.609894</td>\n",
       "      <td>0.722351</td>\n",
       "      <td>2.144394</td>\n",
       "      <td>-1.166077</td>\n",
       "      <td>1.962616</td>\n",
       "      <td>-0.028076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>0.643204</td>\n",
       "      <td>1.847412</td>\n",
       "      <td>-0.722839</td>\n",
       "      <td>2.535858</td>\n",
       "      <td>-0.220520</td>\n",
       "      <td>-0.943481</td>\n",
       "      <td>3.136230</td>\n",
       "      <td>-2.898071</td>\n",
       "      <td>0.966766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.702271</td>\n",
       "      <td>-1.211792</td>\n",
       "      <td>-0.134789</td>\n",
       "      <td>-1.066437</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>-1.379456</td>\n",
       "      <td>2.903175</td>\n",
       "      <td>-1.199646</td>\n",
       "      <td>1.380554</td>\n",
       "      <td>1.718262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>0.753540</td>\n",
       "      <td>0.717773</td>\n",
       "      <td>-0.650528</td>\n",
       "      <td>2.113831</td>\n",
       "      <td>-1.660583</td>\n",
       "      <td>-0.490204</td>\n",
       "      <td>0.650208</td>\n",
       "      <td>-0.766724</td>\n",
       "      <td>1.136200</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.064392</td>\n",
       "      <td>-1.623810</td>\n",
       "      <td>0.325500</td>\n",
       "      <td>0.238525</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>-0.449524</td>\n",
       "      <td>1.335938</td>\n",
       "      <td>-0.230530</td>\n",
       "      <td>1.998627</td>\n",
       "      <td>1.014282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   points         0         1         2         3         4         5  \\\n",
       "0      87 -0.364258  0.786743 -0.038315  1.797501 -0.749458 -0.481781   \n",
       "1      87  0.922775  1.643341 -1.001190  2.650461 -0.556315  1.640244   \n",
       "2      87 -0.886719 -0.114258 -2.253662  2.624756 -0.522400 -0.135101   \n",
       "3      87  0.643204  1.847412 -0.722839  2.535858 -0.220520 -0.943481   \n",
       "4      87  0.753540  0.717773 -0.650528  2.113831 -1.660583 -0.490204   \n",
       "\n",
       "          6         7         8  ...       290       291       292       293  \\\n",
       "0  2.205750 -2.917053  0.027161  ... -2.048325 -1.840363 -1.043030 -3.078369   \n",
       "1  1.762878 -2.678284  0.507172  ... -2.076820 -0.422913 -0.375568  0.862671   \n",
       "2  2.016785 -2.015633  2.668503  ... -2.481445 -1.066376 -0.811798  0.280640   \n",
       "3  3.136230 -2.898071  0.966766  ... -0.702271 -1.211792 -0.134789 -1.066437   \n",
       "4  0.650208 -0.766724  1.136200  ... -1.064392 -1.623810  0.325500  0.238525   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  1.085205  0.373444  0.347908 -0.657639  1.683472  2.301544  \n",
       "1 -0.212234  0.177979  2.442276 -1.439209  2.908058  2.351929  \n",
       "2  0.609894  0.722351  2.144394 -1.166077  1.962616 -0.028076  \n",
       "3  0.064209 -1.379456  2.903175 -1.199646  1.380554  1.718262  \n",
       "4  0.733032 -0.449524  1.335938 -0.230530  1.998627  1.014282  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"description\"] = vectorized_sentences\n",
    "df = df[[\"description\", \"points\"]]\n",
    "df2 = pd.DataFrame(df.description.values.tolist(), index= df.index)\n",
    "df_final = pd.concat([df[\"points\"], df2], axis=1)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out it is a traditional regression task.  We will be focusing on using primarily linear models and comparing their performance.  It seems from an initial performance check, it would seem that OLS and Ridge are the best models as Lasso/Elastic Net performance imply that this data doesn't resond well to L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.iloc[:,1:]\n",
    "y = df_final.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS average cv score:  0.6044429152817308\n",
      "Ridge average cv score:  0.6044452894820764\n",
      "Lasso average cv score:  0.2588743254322418\n",
      "ElasticNet average cv score:  0.37803716421264333\n"
     ]
    }
   ],
   "source": [
    "print(\"OLS average cv score: \", np.mean(cross_val_score(LinearRegression(), X_train, y_train, cv=5)))\n",
    "print(\"Ridge average cv score: \", np.mean(cross_val_score(Ridge(), X_train, y_train, cv=5)))\n",
    "print(\"Lasso average cv score: \", np.mean(cross_val_score(Lasso(), X_train, y_train, cv=5)))\n",
    "print(\"ElasticNet average cv score: \", np.mean(cross_val_score(ElasticNet(), X_train, y_train, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slightly improve performance by using a CatBoostRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost average cv score:  0.6373447621897614\n"
     ]
    }
   ],
   "source": [
    "print(\"CatBoost average cv score: \", np.mean(cross_val_score(CatBoostRegressor(silent=True), X_train, y_train, cv=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the Two Approaches\n",
    "We will now try to combine our approaches from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"./clean_wine2.csv\")\n",
    "df2 = df2.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df2,df_final.iloc[:,1:]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After concatenating both dataframes, we try  Ridge and CatBoost.  Both show a significant improvement as compared to using each of them singularly.  We finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_combined.iloc[:,1:]\n",
    "y = df_combined.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge average cv score:  0.6862580662234377\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge average cv score: \", np.mean(cross_val_score(Ridge(), X_train, y_train, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost average cv score:  0.7171070452227163\n"
     ]
    }
   ],
   "source": [
    "print(\"CatBoost average cv score: \", np.mean(cross_val_score(CatBoostRegressor(silent=True), X_train, y_train, cv=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CatBoostRegressor(silent=True).fit(X_train, y_train).score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
